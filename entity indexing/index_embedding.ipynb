{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UniProt (Universal Protein Resource) is a comprehensive, high-quality database of protein sequence and functional information. It provides detailed annotations on protein functions, structures, interactions, and taxonomy, integrating data from multiple sources. UniProt is widely used in bioinformatics, molecular biology, and biomedical research for studying proteins across different organisms. The database is accessible via a SPARQL endpoint, allowing structured queries on protein-related data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON  # Re-import SPARQLWrapper\n",
    "import pandas as pd\n",
    "import httpx\n",
    "import os\n",
    "import certifi\n",
    "from qdrant_client import QdrantClient, models\n",
    "from langchain_qdrant import QdrantVectorStore, RetrievalMode, FastEmbedSparse\n",
    "from langchain_community.embeddings import FastEmbedEmbeddings\n",
    "import time \n",
    "from fastembed import SparseTextEmbedding, SparseEmbedding\n",
    "from typing import List\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# set parameters\n",
    "collection_name = \"indexed_classes\"\n",
    "\n",
    "\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "\n",
    "endpoint_url = \"https://sparql.uniprot.org/sparql\"\n",
    "sparql = SPARQLWrapper(endpoint_url)  # Initialize SPARQLWrapper\n",
    "sparql.setReturnFormat(JSON)  # Set return format to JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'prithivida/Splade_PP_en_v1',\n",
       "  'sources': {'hf': 'Qdrant/SPLADE_PP_en_v1', 'url': None},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Independent Implementation of SPLADE++ Model for English.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.532,\n",
       "  'additional_files': [],\n",
       "  'requires_idf': None,\n",
       "  'vocab_size': 30522},\n",
       " {'model': 'prithvida/Splade_PP_en_v1',\n",
       "  'sources': {'hf': 'Qdrant/SPLADE_PP_en_v1', 'url': None},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Independent Implementation of SPLADE++ Model for English.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.532,\n",
       "  'additional_files': [],\n",
       "  'requires_idf': None,\n",
       "  'vocab_size': 30522},\n",
       " {'model': 'Qdrant/bm42-all-minilm-l6-v2-attentions',\n",
       "  'sources': {'hf': 'Qdrant/all_miniLM_L6_v2_with_attentions', 'url': None},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Light sparse embedding model, which assigns an importance score to each token in the text',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': ['stopwords.txt'],\n",
       "  'requires_idf': True,\n",
       "  'vocab_size': 30522},\n",
       " {'model': 'Qdrant/bm25',\n",
       "  'sources': {'hf': 'Qdrant/bm25', 'url': None},\n",
       "  'model_file': 'mock.file',\n",
       "  'description': 'BM25 as sparse embeddings meant to be used with Qdrant',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.01,\n",
       "  'additional_files': ['arabic.txt',\n",
       "   'azerbaijani.txt',\n",
       "   'basque.txt',\n",
       "   'bengali.txt',\n",
       "   'catalan.txt',\n",
       "   'chinese.txt',\n",
       "   'danish.txt',\n",
       "   'dutch.txt',\n",
       "   'english.txt',\n",
       "   'finnish.txt',\n",
       "   'french.txt',\n",
       "   'german.txt',\n",
       "   'greek.txt',\n",
       "   'hebrew.txt',\n",
       "   'hinglish.txt',\n",
       "   'hungarian.txt',\n",
       "   'indonesian.txt',\n",
       "   'italian.txt',\n",
       "   'kazakh.txt',\n",
       "   'nepali.txt',\n",
       "   'norwegian.txt',\n",
       "   'portuguese.txt',\n",
       "   'romanian.txt',\n",
       "   'russian.txt',\n",
       "   'slovene.txt',\n",
       "   'spanish.txt',\n",
       "   'swedish.txt',\n",
       "   'tajik.txt',\n",
       "   'turkish.txt'],\n",
       "  'requires_idf': True,\n",
       "  'vocab_size': 0}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SparseTextEmbedding.list_supported_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_query = \"\"\"SELECT DISTINCT ?class ?label ?comment\n",
    "WHERE {\n",
    "  ?class a rdfs:Class .\n",
    "  OPTIONAL { ?class rdfs:label ?label }\n",
    "  OPTIONAL { ?class rdfs:comment ?comment }\n",
    "}\n",
    "ORDER BY ?class\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 206561 classes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'type': 'literal', 'value': 'Published in:\n",
       "Fr...</td>\n",
       "      <td>{'type': 'literal', 'value': 'pentanamide + H2...</td>\n",
       "      <td>{'type': 'uri', 'value': 'http://rdf.rhea-db.o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'uri', 'value': 'http://rdf.rhea-db.o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type': 'uri', 'value': 'http://rdf.rhea-db.o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'type': 'literal', 'value': 'Published in:\n",
       "Fr...</td>\n",
       "      <td>{'type': 'literal', 'value': 'pentanamide + H2...</td>\n",
       "      <td>{'type': 'uri', 'value': 'http://rdf.rhea-db.o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'type': 'literal', 'value': 'Published in:\n",
       "Fr...</td>\n",
       "      <td>{'type': 'literal', 'value': 'pentanoate + NH4...</td>\n",
       "      <td>{'type': 'uri', 'value': 'http://rdf.rhea-db.o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  \\\n",
       "0  {'type': 'literal', 'value': 'Published in:\n",
       "Fr...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  {'type': 'literal', 'value': 'Published in:\n",
       "Fr...   \n",
       "4  {'type': 'literal', 'value': 'Published in:\n",
       "Fr...   \n",
       "\n",
       "                                               label  \\\n",
       "0  {'type': 'literal', 'value': 'pentanamide + H2...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  {'type': 'literal', 'value': 'pentanamide + H2...   \n",
       "4  {'type': 'literal', 'value': 'pentanoate + NH4...   \n",
       "\n",
       "                                               class  \n",
       "0  {'type': 'uri', 'value': 'http://rdf.rhea-db.o...  \n",
       "1  {'type': 'uri', 'value': 'http://rdf.rhea-db.o...  \n",
       "2  {'type': 'uri', 'value': 'http://rdf.rhea-db.o...  \n",
       "3  {'type': 'uri', 'value': 'http://rdf.rhea-db.o...  \n",
       "4  {'type': 'uri', 'value': 'http://rdf.rhea-db.o...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparql.setQuery(uniprot_query)  # Set the query\n",
    "results = sparql.query().convert()  # Execute the query and convert results\n",
    "\n",
    "\n",
    "# Create DataFrame from results\n",
    "classes_df = pd.DataFrame(results[\"results\"][\"bindings\"])\n",
    "print(f\"Found {len(classes_df)} classes\")\n",
    "classes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'comment': {'type': 'literal', 'value': 'Published in:\\nFriedich, C.G. and Mitrenga, G. \\nUtilization of aliphatic amides and formation of two different amidases by <ital>Alcaligenes eutrophus</ital>.\\n<ital>J. Gen. Microbiol.</ital> 125 (1981) 367â€“374.'}, 'label': {'type': 'literal', 'value': 'pentanamide + H2O = pentanoate + NH4(+)'}, 'class': {'type': 'uri', 'value': 'http://rdf.rhea-db.org/10000'}}\n"
     ]
    }
   ],
   "source": [
    "print(results[\"results\"][\"bindings\"][0])\n",
    "\n",
    "#print(results[\"results\"][\"bindings\"][0][\"comment\"][\"value\"])\n",
    "# TODO: - filter out labels that are Nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from qdrant_client.http import models\n",
    "import pandas as pd\n",
    "import certifi\n",
    "import os\n",
    "import uuid\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def process_results(results: Dict[str, Any], filter_empty: bool = True) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Process SPARQL results into document format.\n",
    "    \n",
    "    Args:\n",
    "        results: SPARQL query results\n",
    "        filter_empty: Whether to filter out entries with both empty labels and comments\n",
    "        \n",
    "    Returns:\n",
    "        List of processed documents\n",
    "    \"\"\"\n",
    "    logger.info(\"Processing SPARQL results\")\n",
    "    \n",
    "    # Create DataFrame for easier processing\n",
    "    df = pd.DataFrame(results[\"results\"][\"bindings\"])\n",
    "    \n",
    "    if filter_empty:\n",
    "        total_count = len(df)\n",
    "        \n",
    "        has_label = df['label'].notna()\n",
    "        has_comment = df['comment'].notna()\n",
    "        keep_mask = has_label | has_comment\n",
    "        \n",
    "        df = df[keep_mask]\n",
    "        \n",
    "        filtered_count = len(df)\n",
    "        logger.info(f\"Filtered {total_count - filtered_count} entries with both empty labels and comments. Kept {filtered_count} entries.\")\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    for _, item in df.iterrows():\n",
    "        \n",
    "        # Safely extract values, handling NaN values\n",
    "        uri = ''\n",
    "        if pd.notna(item.get('class')):\n",
    "            uri = item['class'].get('value', '')\n",
    "            \n",
    "        label = ''\n",
    "        if pd.notna(item.get('label')):\n",
    "            label = item['label'].get('value', '')\n",
    "            \n",
    "        comment = ''\n",
    "        if pd.notna(item.get('comment')):\n",
    "            comment = item['comment'].get('value', '')\n",
    "        \n",
    "        # Create a combined text representation\n",
    "        parts = []\n",
    "        if label:\n",
    "            parts.append(f\"Label: {label}\")\n",
    "        if comment:\n",
    "            parts.append(f\"Description: {comment}\")\n",
    "            \n",
    "        # Always include the URI\n",
    "        uri_name = uri.split('/')[-1] if '/' in uri else uri\n",
    "        parts.append(f\"URI: {uri_name}\")\n",
    "        \n",
    "        content = \" \".join(parts)\n",
    "        \n",
    "        doc = Document(\n",
    "            page_content=content,\n",
    "            metadata={\n",
    "                \"uri\": uri,\n",
    "                \"original_label\": label,\n",
    "                \"original_comment\": comment,\n",
    "                \"type\": \"class\"\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    \n",
    "    logger.info(f\"Converted {len(documents)} classes to documents\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-02 11:35:51,813 - __main__ - INFO - Processing SPARQL results\n",
      "2025-03-02 11:35:51,992 - __main__ - INFO - Filtered 135786 entries with both empty labels and comments. Kept 70775 entries.\n",
      "2025-03-02 11:35:53,735 - __main__ - INFO - Converted 70775 classes to documents\n"
     ]
    }
   ],
   "source": [
    "documents = process_results(results = results, filter_empty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "client = QdrantClient(host=\"localhost\", grpc_port=6334, prefer_grpc=True)\n",
    "\n",
    "client.set_model(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "client.set_sparse_model(\"prithivida/Splade_PP_en_v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection already exists\n",
      "Available vectors: dict_keys(['fast-all-minilm-l6-v2'])\n"
     ]
    }
   ],
   "source": [
    "# if client.collection_exists(collection_name):\n",
    "#    print(\"Collection already exists\")\n",
    "#    client.delete_collection(collection_name)\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=client.get_fastembed_vector_params(),\n",
    "    # comment this line to use dense vectors only\n",
    "    sparse_vectors_config=client.get_fastembed_sparse_vector_params(),  \n",
    ")\n",
    "\n",
    "collection_info = client.get_collection(collection_name=collection_name)\n",
    "print(\"Available vectors:\", collection_info.config.params.vectors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectordb = QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        embedding=FastEmbedEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "        sparse_embedding=FastEmbedSparse(model_name=\"prithivida/Splade_PP_en_v1\"),\n",
    "        vector_name=\"fast-all-minilm-l6-v2\",\n",
    "        sparse_vector_name=\"fast-sparse-splade_pp_en_v1\",\n",
    "        retrieval_mode=RetrievalMode.HYBRID,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 206561 documents to Qdrant in 20516.31 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()  # Record start time\n",
    "\n",
    "vectordb.add_documents(documents, batch_size=100)\n",
    "\n",
    "end_time = time.time()  # Record end time\n",
    "\n",
    "# Calculate duration\n",
    "duration = end_time - start_time\n",
    "print(f\"Added {len(documents)} documents to Qdrant in {duration:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
